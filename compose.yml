services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    env_file:
      - .env
    environment:
      - TEXT_EMBEDDING_MODEL=${TEXT_EMBEDDING_MODEL:?"Error TEXT_EMBEDDING_MODEL is required"}
    entrypoint: ["/bin/bash", "-c"]
    command: >
      "ollama serve &
      pid=$!
      sleep 5 &&
      ollama pull llama3.2:latest &&
      ollama pull $${TEXT_EMBEDDING_MODEL} &&
      wait $$pid"
    volumes:
      - ollama:/root/.ollama
volumes:
  ollama:
